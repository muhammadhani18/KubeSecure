{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class CLSTMAnomalyDetector:\n",
    "    \"\"\"\n",
    "    A class to build and train a Convolutional-LSTM (CLSTM) model for anomaly detection.\n",
    "    \n",
    "    Attributes:\n",
    "    -----------\n",
    "    lookback : int\n",
    "        The number of previous timesteps to consider for each sequence.\n",
    "    model : tf.keras.Model\n",
    "        The CLSTM model.\n",
    "    history : History object\n",
    "        Stores model training history.\n",
    "    input_shape : tuple\n",
    "        The shape of the input data for the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lookback=10):\n",
    "        \"\"\"Initialize the CLSTMAnomalyDetector with the given lookback period.\"\"\"\n",
    "        self.lookback = lookback\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.input_shape = None\n",
    "    \n",
    "    def prepare_sequences(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Convert data into sequences of the given lookback size.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : np.ndarray\n",
    "            The input feature array.\n",
    "        y : np.ndarray or None, optional\n",
    "            The target array (if available).\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            The sequence data as an array.\n",
    "        \"\"\"\n",
    "        sequences_X = []\n",
    "        sequences_y = []\n",
    "        \n",
    "        for i in range(len(X) - self.lookback):\n",
    "            sequences_X.append(X[i:(i + self.lookback)])\n",
    "            if y is not None:\n",
    "                sequences_y.append(y[i + self.lookback])\n",
    "        \n",
    "        if y is not None:\n",
    "            return np.array(sequences_X), np.array(sequences_y)\n",
    "        return np.array(sequences_X)\n",
    "    \n",
    "    def build_model(self, input_shape):\n",
    "        \"\"\"\n",
    "        Build the CLSTM model architecture.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_shape : tuple\n",
    "            Shape of the input data (timesteps, features).\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        tf.keras.Model\n",
    "            The compiled CLSTM model.\n",
    "        \"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        model = Sequential([\n",
    "            # First Convolutional Layer\n",
    "            Conv1D(filters=64, kernel_size=3, activation='relu', \n",
    "                  input_shape=input_shape, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            \n",
    "            # Second Convolutional Layer\n",
    "            Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "            \n",
    "            # LSTM Layers\n",
    "            LSTM(128, return_sequences=True),\n",
    "            Dropout(0.3),\n",
    "            LSTM(64),\n",
    "            Dropout(0.3),\n",
    "            \n",
    "            # Dense Layers for classification\n",
    "            Dense(64, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.3),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "        ])\n",
    "        \n",
    "        # Compile the model with Adam optimizer and binary crossentropy loss\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=50, batch_size=64):\n",
    "        \"\"\"\n",
    "        Train the CLSTM model with training and validation data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_train : np.ndarray\n",
    "            Training features.\n",
    "        y_train : np.ndarray\n",
    "            Training labels.\n",
    "        X_val : np.ndarray\n",
    "            Validation features.\n",
    "        y_val : np.ndarray\n",
    "            Validation labels.\n",
    "        epochs : int, optional\n",
    "            Number of training epochs.\n",
    "        batch_size : int, optional\n",
    "            Batch size for training.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        History object\n",
    "            The training history.\n",
    "        \"\"\"\n",
    "        # Train the model with early stopping based on validation loss\n",
    "        self.history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss', patience=5, restore_best_weights=True\n",
    "            )]\n",
    "        )\n",
    "        return self.history\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot the training and validation loss and accuracy over epochs.\"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Plot loss over epochs\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.history.history['loss'], label='Training Loss')\n",
    "        plt.plot(self.history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot accuracy over epochs\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_confusion_matrix(self, y_true, y_pred):\n",
    "        \"\"\"Plot the confusion matrix for the true and predicted labels.\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred.round())\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load data, train the CLSTM model, and evaluate it.\n",
    "    \"\"\"\n",
    "    # Load preprocessed data\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(\"preprocessed_ddos_dataset_1.csv\")\n",
    "    \n",
    "    # Separate features (X) and target (y)\n",
    "    X = df.drop('Label', axis=1).values\n",
    "    y = (df['Label'] != 0).astype(int)  # Convert labels to binary (0 or 1)\n",
    "    \n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Initialize the anomaly detector\n",
    "    print(\"Preparing sequences...\")\n",
    "    detector = CLSTMAnomalyDetector(lookback=10)\n",
    "    \n",
    "    # Prepare sequences for the CLSTM model\n",
    "    X_train_seq, y_train_seq = detector.prepare_sequences(X_train, y_train)\n",
    "    X_val_seq, y_val_seq = detector.prepare_sequences(X_val, y_val)\n",
    "    X_test_seq, y_test_seq = detector.prepare_sequences(X_test, y_test)\n",
    "    \n",
    "    # Build and train the CLSTM model\n",
    "    print(\"Building and training model...\")\n",
    "    detector.build_model(input_shape=(X_train_seq.shape[1], X_train_seq.shape[2]))\n",
    "    detector.model.summary()  # Display model architecture\n",
    "    \n",
    "    # Train the model\n",
    "    history = detector.train(X_train_seq, y_train_seq, X_val_seq, y_val_seq, epochs=50, batch_size=64)\n",
    "    \n",
    "    # Evaluate the model on test data\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    test_loss, test_accuracy = detector.model.evaluate(X_test_seq, y_test_seq)\n",
    "    print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Make predictions on test data\n",
    "    y_pred = detector.model.predict(X_test_seq)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_seq, y_pred.round()))\n",
    "    \n",
    "    # Plot the training history and confusion matrix\n",
    "    detector.plot_training_history()\n",
    "    detector.plot_confusion_matrix(y_test_seq, y_pred)\n",
    "    \n",
    "    # Save the trained model\n",
    "    detector.model.save('clstm_anomaly_detector.h5')\n",
    "    print(\"\\nModel saved as 'clstm_anomaly_detector.h5'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
